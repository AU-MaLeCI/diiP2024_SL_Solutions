{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D53KDb2hVU_X"
      },
      "source": [
        "# Regression-based classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install matplotlib scikit-learn seaborn numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Prepare imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z7zspfLVU_Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_digits # This is to load the dataset\n",
        "from sklearn.decomposition import PCA  # This is to load PCA to be used to transform digits into a 2D points dataset\n",
        "import matplotlib.pyplot as plt # This is to load plotting functions\n",
        "import seaborn as sns; sns.set() # This is to make the plots prettier\n",
        "import numpy as np # This is used to handle arrays of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data\n",
        "\n",
        "We will be working with a dataset of handwritten digits belonging to two classes.\n",
        "Let us visualise some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGS3hu3IVU_Z"
      },
      "outputs": [],
      "source": [
        "# We're using a subset of two classes for now\n",
        "digits = load_digits(n_class=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzXYhCKYVU_Z"
      },
      "outputs": [],
      "source": [
        "# Handy plotting functions\n",
        "x_min, x_max = -40, 40\n",
        "y_min, y_max = -40, 40\n",
        "\n",
        "def plot_examples():\n",
        "    show_num = 4\n",
        "    _, axes = plt.subplots(1, show_num)\n",
        "    images_and_labels = list(zip(digits.images, digits.target))\n",
        "    for ax, (image, label) in zip(axes[:], images_and_labels[:show_num]):\n",
        "        ax.set_axis_off()\n",
        "        ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "        ax.set_title('Label: %i' % label)\n",
        "\n",
        "def plot_scatter(data, target, n_class=2, alpha=0.5):\n",
        "    scatter = plt.scatter(data[:, 0], data[:, 1], c=target, edgecolor='none', alpha=alpha, cmap=plt.cm.get_cmap('rainbow', n_class))\n",
        "    plt.legend(*scatter.legend_elements(), loc=\"upper left\", title=\"Targets\")\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.xlim(x_min, x_max)\n",
        "    plt.ylim(y_min, y_max)\n",
        "\n",
        "def plot_decision_boundary(data, weights):\n",
        "    weights = weights.flatten()\n",
        "    intersection = weights[0]\n",
        "    slope = - weights[1] / weights[2]\n",
        "    xx = np.linspace(x_min, x_max)\n",
        "    yy = slope * xx - intersection\n",
        "    plt.plot(xx, yy, 'k--')\n",
        "    plt.xlim(x_min, x_max)\n",
        "    plt.ylim(y_min, y_max)\n",
        "\n",
        "def plot_mesh(X, pred_fn, n_class=2):\n",
        "    h = 0.1  # step size in the mesh\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = pred_fn(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, alpha = 0.1, cmap=plt.cm.get_cmap('rainbow', n_class))\n",
        "    plt.axis('tight')\n",
        "    plt.xlim(x_min, x_max)\n",
        "    plt.ylim(y_min, y_max)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Qw1wfSx3VU_Z",
        "outputId": "3ea4dd70-eb49-438a-99cb-1e970568e625"
      },
      "outputs": [],
      "source": [
        "plot_examples()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsDuAjyfVU_Z",
        "outputId": "b54b8414-cbb5-45e4-cf94-4bba46ca240c"
      },
      "outputs": [],
      "source": [
        "# The dataset contains 2D data in the form of the `images` attribute,\n",
        "# as well as a 1D-version called `data`, where the images have been flattened.\n",
        "# Here we check that they are identical\n",
        "np.array_equal(digits.images[0].flatten(), digits.data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### We can get a 2D version of the data using PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHQ9q31OVU_a"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "X = pca.fit_transform(digits.data) # This is the representation, we will be working with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0DsetnOVU_a"
      },
      "outputs": [],
      "source": [
        "# Our targets (labels) are in the set {0,1}\n",
        "t_01 = digits.target\n",
        "t_01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "qgrCx5DKVU_a",
        "outputId": "5deecefc-4cc2-42f8-cd11-c8011b07a62b"
      },
      "outputs": [],
      "source": [
        "# Let's plot all the data points in 2D\n",
        "plot_scatter(X, t_01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjMTMvb6VU_a"
      },
      "source": [
        "## Least Squares for classification\n",
        "\n",
        "### Calculate the weight vector using Least Squares regression from the data `X` to the target `t_01`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV9Tpr-OVU_a"
      },
      "outputs": [],
      "source": [
        "# Augment X with ones\n",
        "def augment(X):\n",
        "    \"\"\" Augment with bias component: phi_0(x) = 1 \"\"\"\n",
        "    return np.hstack((np.ones((len(X),1)), X))\n",
        "\n",
        "X_tilde = augment(X).T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U55av2AVU_b",
        "outputId": "31dd95f9-e2cd-4505-95ff-9a67238e7090"
      },
      "outputs": [],
      "source": [
        "# Check an example\n",
        "X_tilde[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We need to do a one_hot encoding of our data: 0 -> [1,0], 1 -> [0,1]\n",
        "def one_hot(targets, n_class):\n",
        "    res = np.eye(n_class)[np.array(targets).reshape(-1)]\n",
        "    return res.reshape(list(targets.shape)+[n_class])\n",
        "\n",
        "t_01_tilde = one_hot(t_01, 2)\n",
        "t_01_tilde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compute the weight vector mapping `X_tilde` to `t_01` (following slide 14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "    <code>\n",
        "    W_tilde = np.linalg.pinv(X_tilde.T) @ t_01_tilde<br>\n",
        "    W_tilde<br>\n",
        "    </code>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efD11mSbVU_b",
        "outputId": "19ca014a-0607-4084-dc4e-680d5e4bda2c"
      },
      "outputs": [],
      "source": [
        "# Compute the weight vector\n",
        "W_tilde = ...\n",
        "W_tilde"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPmSJRMGVU_b"
      },
      "source": [
        "### Create class predictions using the weight vector (follow slide 12)\n",
        "You should be able to correctly classify all data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "    <code>\n",
        "    Y = W_tilde.T @ X_tilde <br>\n",
        "    preds = np.argmax(Y, axis=0)<br>\n",
        "    </code>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57sHMFNbVU_b"
      },
      "outputs": [],
      "source": [
        "def predict(W_tilde, X_tilde):\n",
        "    Y = ...\n",
        "    preds = ...\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UfVMe_DVU_b"
      },
      "outputs": [],
      "source": [
        "preds = predict(W_tilde, X_tilde)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDstHm9zVU_b",
        "outputId": "e1060173-7dea-4e50-9161-ec1f2ace4b10"
      },
      "outputs": [],
      "source": [
        "# Verify that all data points are classified correctly\n",
        "np.array_equal(t_01, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwsLqddzVU_b"
      },
      "source": [
        "#### Plot the decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "Iu3H9tcTVU_b",
        "outputId": "9c9c0117-7f96-4971-d23e-0f701a5db659"
      },
      "outputs": [],
      "source": [
        "plot_scatter(X, preds)\n",
        "plot_decision_boundary(X, W_tilde.T)\n",
        "plot_mesh(X, lambda x: predict(W_tilde, augment(x).T), n_class=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywl823YSVU_c"
      },
      "source": [
        "## Logistic Regression\n",
        "#### Train and test the Logistic Regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S0afLzKVU_c"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.1 # This is the rate of change on each update\n",
        "\n",
        "X_train = augment(X)\n",
        "\n",
        "# Initialise W_0 randomly\n",
        "np.random.seed(42)\n",
        "W_0 = 2 * np.random.random((1, X_train.shape[1])) -1 # random values in the range [-1,1]\n",
        "\n",
        "# Our target vectors should be {0, 1}\n",
        "digits = load_digits(n_class=2)\n",
        "t = digits.target\n",
        "t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define the sigmoid function (following slide 20) and the error function (gradient of E(w) from slide 23)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "    <code>\n",
        "    s = 1/ (1 + np.exp(-a))\n",
        "    </code>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLv_ND8mVU_c"
      },
      "outputs": [],
      "source": [
        "def sigmoid(a):\n",
        "    s = ...\n",
        "    return s\n",
        "\n",
        "def error(W, X, t):\n",
        "    y = sigmoid(W @ X.T).flatten()\n",
        "    yt = (y - t)\n",
        "    yt = np.broadcast_to(np.expand_dims(yt,axis=1), X.shape)\n",
        "    return np.sum(yt*X, axis=0)/len(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train the Logistic Regression classifier iteratively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhBb_pScVU_c"
      },
      "outputs": [],
      "source": [
        "W_log_list = [W_0] # We start from a randomly initialized W_0\n",
        "for epoch in range(30):\n",
        "    # Add the updated W for new epoch to the list of Ws\n",
        "    W_log_list.append(W_log_list[epoch] - learning_rate * error(W_log_list[epoch], X_train, t))\n",
        "\n",
        "W_logistic = W_log_list[-1] # Keep the final W as the parameters of the logistic regression \n",
        "W_logistic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GgFY3hhVU_c"
      },
      "source": [
        "### Perform class-predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_logistic(W_logistic, X_train, boundary=0.5):\n",
        "    y = sigmoid(W_logistic @ X_train.T)[0]\n",
        "    preds = np.array(y > boundary, dtype=int)\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQcXenAbVU_c",
        "outputId": "a28b4af1-031c-4425-8d5e-2fad8f2da76e"
      },
      "outputs": [],
      "source": [
        "preds = predict_logistic(W_logistic, X_train)\n",
        "np.array_equal(preds, t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJwgBDxSVU_c"
      },
      "source": [
        "### Plot the decision boundary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "7Y8TvBcHVU_c",
        "outputId": "942bc3f0-530c-40ad-d67f-a40ab5a6ffb6"
      },
      "outputs": [],
      "source": [
        "plot_scatter(X, preds)\n",
        "plot_mesh(X, lambda x: predict_logistic(W_logistic, augment(x)), n_class=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egAV6s9BVU_d"
      },
      "source": [
        "## Multi-class Logistic Regression\n",
        "#### Train a Logistic Regression classifier for 3 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC502SkvVU_d"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "n_class = 3\n",
        "digits = load_digits(n_class=n_class)\n",
        "pca = PCA(n_components=2)\n",
        "X_mult = pca.fit_transform(digits.data)\n",
        "\n",
        "learning_rate = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJBDrGPoVU_d"
      },
      "outputs": [],
      "source": [
        "X_train_mult = augment(X_mult)\n",
        "\n",
        "t_cat = digits.target\n",
        "# We need to do a one_hot encoding of our data: 1 -> [0,1,0], 2 -> [0,0,1]\n",
        "t_oh = one_hot(digits.target, n_class)\n",
        "t_oh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "hnt5BOUgVU_d",
        "outputId": "3dc7529a-e620-4569-ed65-7f7ae619c18b"
      },
      "outputs": [],
      "source": [
        "plot_scatter(X_mult, t_cat, n_class=n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Define the softmax function (following slide 25) and the gradient function (following slide 27)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<details>\n",
        "<summary>Solution</summary>\n",
        "    <code>\n",
        "    e = np.exp(x - np.max(x))  # prevent overflow<br>\n",
        "    s = e / np.maximum(np.sum(e, axis=0), 1e-16) # prevent divide by zero<br>\n",
        "    return s<br>\n",
        "    </code>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65_Kjz5bVU_d"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    s = ...\n",
        "    return s\n",
        "\n",
        "def grad_error(W, X, t):\n",
        "    y = softmax(W @ X.T).T\n",
        "    yt = (y - t_oh)\n",
        "    yt_wide = np.repeat(yt, X.shape[1],1)\n",
        "    X_wide = np.tile(X, (1, yt.shape[1]))\n",
        "    return np.sum(yt_wide*X_wide, axis=0).reshape(W.shape) / X.shape[0]\n",
        "\n",
        "def predict(W, X):\n",
        "    y = softmax(W @ X.T).T\n",
        "    return np.argmax(y, axis=1)\n",
        "\n",
        "def accuracy(preds, targets):\n",
        "    return np.sum(preds == targets) / len(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initialize the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72rx4FH4VU_d"
      },
      "outputs": [],
      "source": [
        "# Weight initialisation\n",
        "np.random.seed(25)\n",
        "W_0 = 2 * np.random.random((n_class, X_train_mult.shape[1])) - 1\n",
        "W_log_mult = [W_0]\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Display metrics for the untrained classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "_4-rPVWdVU_d",
        "outputId": "1d727327-7f2a-4892-8599-bd86c62145e9"
      },
      "outputs": [],
      "source": [
        "# Print metrics\n",
        "print(\"epoch = {}\".format(epoch))\n",
        "# print(\"weight =  {}\".format(W_log_mult[epoch]))\n",
        "preds = predict(W_log_mult[epoch], X_train_mult)\n",
        "print(\"acc =  {}\".format(accuracy(preds, t_cat)))\n",
        "\n",
        "# Plot updates weight\n",
        "plot_scatter(X_mult, t_cat, n_class=n_class)\n",
        "plot_mesh(X_mult, lambda x: predict(W_log_mult[epoch], augment(x)), n_class=n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train and test the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkrFjy9bVU_d"
      },
      "outputs": [],
      "source": [
        "W_log_mult = [W_0]\n",
        "for epoch in range(50):\n",
        "    W_log_mult.append(W_log_mult[epoch] - learning_rate * grad_error(W_log_mult[epoch], X_train_mult, t_oh))\n",
        "\n",
        "W_multi_logistic = W_log_mult[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "dcWusO9bVU_d",
        "outputId": "d1724cc4-01df-497e-a8b8-36de7eb77168"
      },
      "outputs": [],
      "source": [
        "# Print metrics\n",
        "print(\"epoch = {}\".format(epoch))\n",
        "# print(\"weight =  {}\".format(W_log_mult[epoch]))\n",
        "preds = predict(W_log_mult[epoch], X_train_mult)\n",
        "print(\"acc =  {}\".format(accuracy(preds, t_cat)))\n",
        "\n",
        "# Plot updates weight\n",
        "plot_scatter(X_mult, t_cat, n_class=n_class)\n",
        "plot_mesh(X_mult, lambda x: predict(W_log_mult[epoch], augment(x)), n_class=n_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swvQfA7UVU_d"
      },
      "source": [
        "## Multi-class logistic regression on original data representation\n",
        "Repeat exercise the previous part, but use the original data representation instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kze5FgpVU_e",
        "outputId": "732796fe-098e-4f99-9147-32c40f94e809"
      },
      "outputs": [],
      "source": [
        "def phi(X):\n",
        "    \"\"\" Augment with bias component: phi_0(x) = 1 and squared values \"\"\"\n",
        "    return np.hstack((np.ones((len(X),1)), X, X**2))\n",
        "\n",
        "X_train_mult_orig = phi(digits.data / digits.data.max())\n",
        "X_train_mult_orig.shape #64 + 1 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GkOnyieVU_e",
        "outputId": "51c0ee2f-c382-4b4e-bfed-6407961ec4ac"
      },
      "outputs": [],
      "source": [
        "# Weight initialisation\n",
        "np.random.seed(25)\n",
        "W_0 = 2 * np.random.random((n_class, X_train_mult_orig.shape[1])) - 1\n",
        "W_0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNg65VlnVU_f"
      },
      "outputs": [],
      "source": [
        "W_log_mult_orig = [W_0]\n",
        "for epoch in range(1000):\n",
        "    W_log_mult_orig.append(W_log_mult_orig[epoch] - learning_rate * grad_error(W_log_mult_orig[epoch], X_train_mult_orig, t_oh))\n",
        "\n",
        "W_mult_logistic_orig = W_log_mult_orig[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should be able to achieve 100% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgaQ7FaCVU_g",
        "outputId": "2b0f9f23-03a1-47cf-f079-431bef89dd8a"
      },
      "outputs": [],
      "source": [
        "preds = predict(W_mult_logistic_orig, X_train_mult_orig)\n",
        "print(\"acc =  {}\".format(accuracy(preds, t_cat)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
